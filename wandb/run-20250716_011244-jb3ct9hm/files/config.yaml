_wandb:
    value:
        cli_version: 0.19.9
        m: []
        python_version: 3.13.4
        t:
            "1":
                - 1
                - 55
            "2":
                - 1
                - 55
            "3":
                - 2
                - 14
                - 23
                - 55
                - 61
            "4": 3.13.4
            "5": 0.19.9
            "8":
                - 5
            "12": 0.19.9
            "13": darwin-arm64
batch_size:
    value: 64
beta1:
    value: 0.9
beta2:
    value: 0.999
checkpoint_dir:
    value: checkpoints/TinyStories_LM
context_length:
    value: 256
d_ff:
    value: 1344
d_model:
    value: 512
device:
    value: auto
dtype:
    value: float32
eps:
    value: 1e-08
eval_num:
    value: 2000
grad_accumulation_steps:
    value: 1
learning_rate:
    value: 0.001
log_num:
    value: 2000
lr_decay_steps_ratio:
    value: 1
lr_min_ratio:
    value: 0.1
lr_schedule:
    value: cosine
lr_warmup_steps_ratio:
    value: 0.1
max_grad_norm:
    value: 1
max_tokens:
    value: 327680000
num_heads:
    value: 16
num_layers:
    value: 4
optimizer:
    value: adamw
resume_from:
    value: null
save_num:
    value: 5
seed:
    value: 42
single_minibatch:
    value: false
theta:
    value: 10000
train_data_path:
    value: data/TinyStoriesV2-GPT4-train.npy
val_data_path:
    value: data/TinyStoriesV2-GPT4-valid.npy
vocab_size:
    value: 10000
wandb_project:
    value: CS336_assignment1
weight_decay:
    value: 0.01
